# PostTagger-Reimagined-Test-Task

Test Task project for JetBrains internship application.

## Table of Contents
- [Overview](#overview)
- [Structure](#structure)
- [Prerequisites](#prerequisites)
- [Configuration](#configuration)
- [Running With Docker Compose](#running-with-docker-compose)
- [Available Services & Endpoints](#available-services--endpoints)
- [Task Workflow](#task-workflow)
- [Testing](#testing)

## Overview
This project exposes an HTTP API that allows clients to enqueue long-running jobs (e.g., computing π) and poll for their status. Celery is used as the task queue, Redis serves as broker/backend, and FastAPI provides the HTTP layer.

## Structure
- **FastAPI (src/api/presentation)** — HTTP routing and request handling
- **Application services (src/api/application)** — Orchestrate task creation and status queries
- **Domain (src/api/domain)** — Shared models, repositories, and exceptions
- **Infrastructure (src/api/infrastructure)** — Celery integration and mappers
- **Worker (src/worker/tasks.py)** — Celery task implementations
- **Config (src/setup)** - Configuration files

## Prerequisites
- Python 3.11+
- Redis (local instance or Docker)
- [Pipenv/virtualenv] or equivalent for managing dependencies
- Docker & Docker Compose (optional, for containerized setup)

## Configuration
Environment variables are loaded from `.env`. Copy `.env.example` and adjust as needed:
```bash
cp .env.example .env
```
Key settings:
- `APP_NAME`, `APP_VERSION`
- `REDIS_URL` — broker/backend location
- `MAX_DIGITS` — upper bound for `calculate_pi`
- `RESULT_TTL_SECONDS`, `SLEEP_PER_DIGIT_SEC`, `ROUNDING_POLICY`


## Running With Docker Compose
```bash
docker compose up --build
```
Services started:
- `api` — FastAPI application on `http://localhost:8000`
- `worker` — Celery worker
- `redis` — Redis broker/backend

## Available Services & Endpoints
### API
- `GET /calculate_pi?n=<digits>` — enqueue π computation
- `GET /check_progress?task_id=<id>` — retrieve task progress/result

### Worker
- Task: `compute_pi` defined in `src/worker/tasks.py`

## Task Workflow
1. Client calls `/calculate_pi`.
2. API enqueues `compute_pi` via Celery.
3. Worker updates progress using `update_state` and ultimately stores the result.
4. Client polls `/check_progress` until `state` is `SUCCESS`.


